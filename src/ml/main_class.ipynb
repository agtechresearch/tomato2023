{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(\"data/merged.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment = {\n",
    "        \"PFBS_NTRO_CBDX_CTRN\": \"관측지점실내이산화탄소농도\",\n",
    "        \"ABSLT_HMDT\": \"절대습도\",\n",
    "        \"INNER_HMDT_1\": \"내부습도_1\",\n",
    "        \"INNER_HMDT_2\": \"내부습도_2\",\n",
    "        \"AVE_INNER_HMDT_1_2\": \"평균내부습도_1_2\",\n",
    "        \"WNDRC\": \"풍향\",\n",
    "        \"WDSP\": \"풍속\",\n",
    "        \"STRTN_WATER\": \"포화수분\",\n",
    "        \"EXTN_SRQT\": \"외부일사량\",\n",
    "        \"WATER_LACK_VL\": \"수분부족량\",\n",
    "        \"EXTN_ACCMLT_QOFLG\": \"외부누적광량\",\n",
    "        \"PRCPT_YN\": \"강수여부\",\n",
    "        \"DWP_TPRT\": \"이슬점온도\",\n",
    "        \"EXTN_TPRT\": \"외부온도\",\n",
    "        \"INNER_TPRT_1\": \"내부온도_1\",\n",
    "        \"INNER_TPRT_2\": \"내부온도_2\",\n",
    "        \"AVE_INNER_TPRT_1_2\": \"평균내부온도_1_2\",\n",
    "}\n",
    "\n",
    "df[\"SUB_MHRLS_OPRT_YN\"] = df[[\"SUB_MHRLS_OPRT_YN_1\",\"SUB_MHRLS_OPRT_YN_2\", \"SUB_MHRLS_OPRT_YN_3\"]].apply(\n",
    "    lambda x: 0 if 0 in x.values else 1, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUB_MHRLS_OPRT_YN\n",
      "0    28940\n",
      "1    19444\n",
      "Name: count, dtype: int64\n",
      "관측지점실내이산화탄소농도: \t\t Cov is -10.7342 \t Beta is -44.6559\n",
      "절대습도: \t\t Cov is 0.5911 \t Beta is 2.4592\n",
      "내부습도_1: \t\t Cov is -0.5594 \t Beta is -2.3271\n",
      "내부습도_2: \t\t Cov is -0.2534 \t Beta is -1.0540\n",
      "평균내부습도_1_2: \t\t Cov is -0.4064 \t Beta is -1.6905\n",
      "풍향: \t\t Cov is -1.3323 \t Beta is -5.5427\n",
      "풍속: \t\t Cov is 0.0189 \t Beta is 0.0787\n",
      "포화수분: \t\t Cov is 0.9000 \t Beta is 3.7442\n",
      "외부일사량: \t\t Cov is 21.0940 \t Beta is 87.7546\n",
      "수분부족량: \t\t Cov is 0.3086 \t Beta is 1.2840\n",
      "외부누적광량: \t\t Cov is 65.9143 \t Beta is 274.2143\n",
      "강수여부: \t\t Cov is 0.0142 \t Beta is 0.0593\n",
      "이슬점온도: \t\t Cov is 0.6378 \t Beta is 2.6535\n",
      "외부온도: \t\t Cov is 2.0061 \t Beta is 8.3456\n",
      "내부온도_1: \t\t Cov is 0.7847 \t Beta is 3.2645\n",
      "내부온도_2: \t\t Cov is 0.7182 \t Beta is 2.9877\n",
      "평균내부온도_1_2: \t\t Cov is 0.7514 \t Beta is 3.1261\n"
     ]
    }
   ],
   "source": [
    "print(df[\"SUB_MHRLS_OPRT_YN\"].value_counts())\n",
    "var = df[\"SUB_MHRLS_OPRT_YN\"].var()\n",
    "for k in environment.keys():\n",
    "    covariance = df[\"SUB_MHRLS_OPRT_YN\"].cov(df[k])\n",
    "    print(f\"{environment[k]}: \\t\\t Cov is {covariance:.4f} \\t Beta is {covariance/var:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_cols = environment.keys()\n",
    "y_cols = [\"SUB_MHRLS_OPRT_YN\"]\n",
    "\n",
    "X = df[x_cols].values\n",
    "y = df[y_cols].values.ravel()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SUB_MHRLS_OPRT_YN</th>\n",
       "      <td>48384.0</td>\n",
       "      <td>0.401868</td>\n",
       "      <td>0.490281</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count      mean       std  min  25%  50%  75%  max\n",
       "SUB_MHRLS_OPRT_YN  48384.0  0.401868  0.490281  0.0  0.0  0.0  1.0  1.0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[y_cols].describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "using scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Accuracy: train 0.9960730617201023 test 0.7142709517412421\n",
      "KNeighborsClassifier Accuracy: train 0.9523858733562405 test 0.8923220006200269\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# SVM 모델 정의 및 학습\n",
    "model = SVC(kernel='rbf', C=1, gamma='auto')\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 및 평가\n",
    "y_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'SVC Accuracy: train {train_accuracy} test {test_accuracy}')\n",
    "\n",
    "# KNN 모델 정의 및 학습\n",
    "model = KNeighborsClassifier(n_neighbors=2)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# 테스트 및 평가\n",
    "y_pred = model.predict(X_train)\n",
    "train_accuracy = accuracy_score(y_train, y_pred)\n",
    "y_pred = model.predict(X_test)\n",
    "test_accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'KNeighborsClassifier Accuracy: train {train_accuracy} test {test_accuracy}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM: 성능이 저 둘의 중간일뿐."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# LSTM 모델 정의\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])  # LSTM의 마지막 시퀀스만 사용\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터를 시퀀스로 변환\n",
    "seq_length = 1  # 시퀀스 길이\n",
    "X_sequences = []\n",
    "for i in range(len(X) - seq_length + 1):\n",
    "    X_sequences.append(X[i:i+seq_length])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y = y[seq_length - 1:]  # 레이블을 시퀀스에 맞게 조정\n",
    "\n",
    "\n",
    "# 데이터를 PyTorch Tensor로 변환\n",
    "X_tensor = torch.tensor(X_sequences, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.3298\n",
      "Epoch [21/100], Loss: 0.7945\n",
      "Epoch [31/100], Loss: 0.5782\n",
      "Epoch [41/100], Loss: 0.1897\n",
      "Epoch [51/100], Loss: 0.3416\n",
      "Epoch [61/100], Loss: 0.2379\n",
      "Epoch [71/100], Loss: 0.4609\n",
      "Epoch [81/100], Loss: 0.2952\n",
      "Epoch [91/100], Loss: 0.2494\n",
      "Epoch [101/100], Loss: 0.1468\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수 및 옵티마이저 설정\n",
    "input_size = X_sequences.shape[2]  # 입력 크기: 특성 수\n",
    "hidden_size = 200\n",
    "num_layers = 1\n",
    "output_size = 1  # 출력 크기: 이진 분류이므로 1\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 분류용 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))  # 레이블을 2D로 변환하여 손실 함수에 전달\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8768\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    predicted = (torch.sigmoid(outputs) > 0.5).float()  # 확률을 기준으로 0 또는 1로 변환\n",
    "    accuracy = accuracy_score(y_tensor, predicted)\n",
    "    print(f'Train Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LSTM with Longer sequence: 1->10 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시계열 데이터를 시퀀스로 변환\n",
    "seq_length = 10  # 시퀀스 길이\n",
    "X_sequences = []\n",
    "for i in range(len(X) - seq_length + 1):\n",
    "    X_sequences.append(X[i:i+seq_length])\n",
    "\n",
    "X_sequences = np.array(X_sequences)\n",
    "y = y[seq_length - 1:]  # 레이블을 시퀀스에 맞게 조정\n",
    "\n",
    "\n",
    "# 데이터를 PyTorch Tensor로 변환\n",
    "X_tensor = torch.tensor(X_sequences, dtype=torch.float32)\n",
    "y_tensor = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "# 데이터셋 및 데이터로더 생성\n",
    "dataset = TensorDataset(X_tensor, y_tensor)\n",
    "train_loader = DataLoader(dataset, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Loss: 0.3782\n",
      "Epoch [21/100], Loss: 0.6070\n",
      "Epoch [31/100], Loss: 0.2058\n",
      "Epoch [41/100], Loss: 0.2446\n",
      "Epoch [51/100], Loss: 0.2536\n",
      "Epoch [61/100], Loss: 0.3810\n",
      "Epoch [71/100], Loss: 0.2049\n",
      "Epoch [81/100], Loss: 0.4170\n",
      "Epoch [91/100], Loss: 0.1060\n",
      "Epoch [101/100], Loss: 0.2612\n"
     ]
    }
   ],
   "source": [
    "# 모델, 손실 함수 및 옵티마이저 설정\n",
    "input_size = X_sequences.shape[2]  # 입력 크기: 특성 수\n",
    "hidden_size = 200\n",
    "num_layers = 1\n",
    "output_size = 1  # 출력 크기: 이진 분류이므로 1\n",
    "model = LSTMModel(input_size, hidden_size, num_layers, output_size)\n",
    "criterion = nn.BCEWithLogitsLoss()  # 이진 분류용 손실 함수\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "\n",
    "# 학습\n",
    "num_epochs = 100\n",
    "for epoch in range(1, num_epochs+1):\n",
    "    for inputs, targets in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets.unsqueeze(1))  # 레이블을 2D로 변환하여 손실 함수에 전달\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9122\n"
     ]
    }
   ],
   "source": [
    "# 평가\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "with torch.no_grad():\n",
    "    outputs = model(X_tensor)\n",
    "    predicted = (torch.sigmoid(outputs) > 0.5).float()  # 확률을 기준으로 0 또는 1로 변환\n",
    "    accuracy = accuracy_score(y_tensor, predicted)\n",
    "    print(f'Train Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "강화학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "# Q-network 구성\n",
    "class QNetwork(nn.Module):\n",
    "    def __init__(self, state_size, action_size, hidden_size):\n",
    "        super(QNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(state_size, hidden_size)\n",
    "        self.fc2 = nn.Linear(hidden_size, action_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Offline Q-learning 알고리즘\n",
    "def offline_q_learning(states, actions, rewards, next_states, dones, q_network, gamma):\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(q_network.parameters(), lr=0.001)\n",
    "    \n",
    "    for i in range(len(states)):\n",
    "        state = states[i]\n",
    "        action = actions[i]\n",
    "        reward = rewards[i]\n",
    "        next_state = next_states[i]\n",
    "        done = dones[i]\n",
    "        \n",
    "        # 목표 Q-value 계산\n",
    "        with torch.no_grad():\n",
    "            if done:\n",
    "                target = reward\n",
    "            else:\n",
    "                target = reward + gamma * torch.max(q_network(torch.tensor(next_state, dtype=torch.float32)))\n",
    "        \n",
    "        # 현재 Q-value 계산\n",
    "        current = q_network(torch.tensor(state, dtype=torch.float32))[action]\n",
    "        \n",
    "        # 손실 계산 및 역전파\n",
    "        loss = criterion(current, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 10, 17]) torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "for i, j in train_loader:\n",
    "    print(i.shape, j.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 미리 수집한 샘플 데이터\n",
    "states = [...] # 상태 데이터\n",
    "actions = [...] # 행동 데이터\n",
    "rewards = [...] # 보상 데이터\n",
    "next_states = [...] # 다음 상태 데이터\n",
    "dones = [...] # 종료 여부 데이터\n",
    "\n",
    "# 환경 설정\n",
    "state_size = len(states[0])\n",
    "action_size = len(actions[0])\n",
    "\n",
    "# 하이퍼파라미터 설정\n",
    "hidden_size = 64\n",
    "gamma = 0.99\n",
    "\n",
    "# Q-network 초기화 및 학습\n",
    "q_network = QNetwork(state_size, action_size, hidden_size)\n",
    "offline_q_learning(states, actions, rewards, next_states, dones, q_network, gamma)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 50, 3) (1000,)\n",
      "(50, 3) (150,)\n",
      "Predictions: [1 1 1 1 0 0 0 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# 3차원 시계열 데이터 생성\n",
    "# 각 데이터 포인트는 (seq_length, num_features) 형태의 2차원 배열로 가정\n",
    "def generate_time_series_3d(num_samples, seq_length, num_features):\n",
    "    X = np.random.randn(num_samples, seq_length, num_features)\n",
    "    y = np.random.randint(2, size=num_samples)\n",
    "    return X, y\n",
    "\n",
    "# 데이터 생성\n",
    "num_samples = 1000\n",
    "seq_length = 50\n",
    "num_features = 3  # 각 시간 단계에서의 특징 수\n",
    "X, y = generate_time_series_3d(num_samples, seq_length, num_features)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "# 3차원 데이터를 2차원으로 변환\n",
    "X_2d = X.reshape(num_samples, -1)\n",
    "print(X[0].shape, X_2d[0].shape)\n",
    "\n",
    "# SVM Classifier 초기화 및 훈련\n",
    "svm_clf = SVC(kernel='linear')\n",
    "svm_clf.fit(X_2d, y)\n",
    "\n",
    "# 새로운 데이터에 대한 예측\n",
    "new_data = np.random.randn(10, seq_length, num_features)  # 예시를 위해 임의의 새로운 데이터 생성\n",
    "new_data_2d = new_data.reshape(10, -1)\n",
    "predictions = svm_clf.predict(new_data_2d)\n",
    "print(\"Predictions:\", predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tomato2023",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
